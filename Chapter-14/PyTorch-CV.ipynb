{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a4f1dd6-c8d7-49d8-acaf-a7cd2683c149",
   "metadata": {},
   "source": [
    "# Building a Convolutional Neural Network (CNN) with PyTorch\n",
    "\n",
    "In this notebnook, we will use PyTorch to build a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95821d-7f47-44e4-9959-b45d38570967",
   "metadata": {},
   "source": [
    "**Attention:** The code in this notebook creates Google Cloud resources that can incur costs.\n",
    "\n",
    "Refer to the Google Cloud pricing documentation for details.\n",
    "\n",
    "For example:\n",
    "\n",
    "* [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2c50ee-4a68-49b9-b0f0-450ff307fbd9",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "\n",
    "We start by importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2e5e52-3cc0-4c52-bc0b-5cf8dcf46919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db26a5b5-e730-4265-a47c-23193e5d4ea8",
   "metadata": {},
   "source": [
    "## Load and process the dataset\n",
    "\n",
    "In the next cell, we wil load the [CIFAR-10 dataset](https://keras.io/api/datasets/cifar10/), which is a dataset that consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.  The classes are: 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', and 'truck'. The following is a description of what our code will do.\n",
    "\n",
    "### Define the transformations to be performed on our input data\n",
    "\n",
    "```\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "```\n",
    "This code calls `torchvision.transforms.Compose()` to create a transformation object named `transform` that performs the following steps:\n",
    "* transforms.ToTensor(): Convert each image (PIL Image) to a PyTorch tensor. \n",
    "* transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)): Normalize the pixel values of each image by subtracting the mean value (0.5) from each color channel (red, green, blue), and dividing each channel by its standard deviation (also 0.5 in this case).\n",
    "\n",
    "### Download the datasets\n",
    "```\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "```\n",
    "This code creates two datasets, `trainset` and `testset`, by loading the CIFAR-10 dataset from the torchvision library. We use the following dataset parameters:\n",
    "* root='./data': This specifies the directory where the dataset will be downloaded or stored.\n",
    "* train=True and train=False: This indicates whether to load the training or test split of the dataset.\n",
    "* download=True: This downloads the dataset if it's not already downloaded in our directory.\n",
    "* transform=transform: Applies the previously defined image transformations to the loaded images.\n",
    "\n",
    "### Create data loaders\n",
    "Data loaders are iterators that provide data in batches for training and evaluation.\n",
    "The following code creates two data loaders, `trainloader` and `testloader`, from the loaded datasets:\n",
    "```\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "```\n",
    "The DataLoader parameters are used as follows:\n",
    "* batch_size=4: This specifies the number of images to be included in each batch.\n",
    "* shuffle=True (for trainloader): This randomly shuffles the training data before each epoch to improve model generalization.\n",
    "* shuffle=False (for testloader): This maintains the original order of the test data for consistent evaluation.\n",
    "* num_workers=2: This specifies the number of subprocesses to use for data loading (using multiple workers can improve the performance by parallelizing data loading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da43d6cd-9bed-4772-ad44-b3b3f114c29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations to be applied on each image of CIFAR-10\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Loading the training set and test set of CIFAR-10\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46b9809-7865-4e61-b77a-d5bc27b836ca",
   "metadata": {},
   "source": [
    "## Define our CNN model\n",
    "\n",
    "The code in the next cell will define a CNN with the following layers (see the descriptions in the text in Chapter-14 in our book for reference):\n",
    "\n",
    "* **Convolutional layers:** These layers extract features from the input images using filters. \n",
    "* **Max pooling layers:** These layers reduce the dimensionality of the features, making the model more efficient and less prone to overfitting. We also downsample the input by taking the maximum value in 2x2 patches.\n",
    "* **Linear layers:** These are fully connected layers that perform the final classification. The first fully connected layer takes the flattened input (16 * 5 * 5) from the last convolutional layer, and has 120 neurons, and we then add another fully connected layer with 84 neurons. We use ReLU activation for the first two fully connected layers, and then we define an output layer with 10 neurons (one for each class) and softmax activation to produce probability scores. This is what provides the probability at which the input image was a member of each class.\n",
    "\n",
    "The `forward` function defines how input data (x) flows through the network during the forward pass for inference. We can break it down as follows:\n",
    "\n",
    "### First convolutional block\n",
    "```\n",
    "x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "```\n",
    "This applies the first convolutional block, as follows:\n",
    "* self.conv1(x): Applies the first convolutional layer to the input x, extracting features from the input image.\n",
    "* nn.functional.relu(): Applies the ReLU (Rectified Linear Unit) activation function, introducing non-linearity to the output of the convolutional layer.\n",
    "* self.pool(): Applies max pooling, downsampling the spatial dimensions of the feature maps to reduce computational complexity and enhance spatial invariance.\n",
    "The output of this line, which is a downsampled feature map with non-linear activations, is stored back in `x` for further processing.\n",
    "\n",
    "### Second convolutional block\n",
    "```\n",
    "x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "```\n",
    "This applies the same operations as the previous line, but with the second convolutional layer (self.conv2), further refining the feature representations.\n",
    "\n",
    "### Flattening\n",
    "\n",
    "```\n",
    "x = x.view(-1, 16 * 5 * 5)\n",
    "```\n",
    "This flattens the feature maps by reshaping the output of the convolutional blocks (which are 3D tensors) into a 1D vector, preparing the data to be fed into the fully connected layers. The following are the values used:\n",
    "* -1: Automatically infers the correct dimension for the batch size.\n",
    "* 16 * 5 * 5: Calculates the total number of elements in the flattened feature maps, ensuring that all information is preserved during the reshaping process.\n",
    "\n",
    "### First fully connected layer\n",
    "```\n",
    "x = nn.functional.relu(self.fc1(x))\n",
    "```\n",
    "This applies the first fully connected layer, as follows:\n",
    "* self.fc1(x): Applies the first fully connected layer, performing a linear transformation on the flattened features.\n",
    "* nn.functional.relu(): Applies the ReLU activation function again to introduce non-linearity.\n",
    "\n",
    "### Second fully connected layer\n",
    "```\n",
    "x = nn.functional.relu(self.fc2(x))\n",
    "```\n",
    "This performs the same operations as the previous line, but with the second fully connected layer (self.fc2), further processing the features.\n",
    "\n",
    "### Final fully connected layer\n",
    "\n",
    "```\n",
    "x = self.fc3(x)\n",
    "```\n",
    "This applies the final fully connected layer (self.fc3), producing the output of the network. In this case, no activation function is applied after this layer, as we can leave raw the output values for tasks like classification where probabilities are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f09d8-4cb3-4310-bd76-97f9f383df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Convolutional Neural Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net() # Instantiate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089750ac-1904-42b8-9781-e476d582277d",
   "metadata": {},
   "source": [
    "## Train our CNN model\n",
    "\n",
    "In the next cell, we perform the following steps to train our CNN model:\n",
    "* Specify our loss function (cross entropy for classification) and optimizer (stochastic gradient descent, with a learning rate of 0.001, and momentum of 0.9)\n",
    "* Loop over the dataset multiple times, and in each iteration:\n",
    "1. Perform the forward pass: `outputs = net(inputs)`: This feeds the input images through the neural network (net) to get its predictions (outputs).\n",
    "1. Calculate the loss.\n",
    "1. Perform the backward pass: `loss.backward()`: This starts the backpropagation, which computes the gradients of the loss with respect to the model's parameters. These gradients indicate how much each parameter contributed to the loss and how they should be adjusted to improve performance.\n",
    "1. Update the parameters: `optimizer.step()`: This uses the computed gradients to update the model's parameters in the direction that minimizes the loss. \n",
    "1. Track the loss: `running_loss += loss.item()`: This accumulates the loss over multiple batches to get a more stable estimate of the overall training loss.\n",
    "1. Print the progress ever 2000 batches.\n",
    "1. Reset the loss for the next batch of 2000 iterations: `running_loss = 0.0`\n",
    "\n",
    "When training is finished, we save our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53345a6f-cd35-42b1-999c-f0f85206d31e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Train the network\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Save the trained model\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efcea1-a8d9-4267-9952-ccde7ecb2717",
   "metadata": {},
   "source": [
    "## Load and evaluate our CNN model\n",
    "\n",
    "Next, we will load our saved model and evaluate it. The code in the next cell performs the following steps:\n",
    "\n",
    "### Load the Saved Model:\n",
    "\n",
    "* `net = Net()`: This creates a new instance of the neural network class Net (i.e., an empty model with the defined architecture).\n",
    "* `net.load_state_dict(torch.load(PATH))`: This loads the trained parameters (weights and biases) of the trained model we saved in the previous step.\n",
    "* `net.eval()`: This puts the model into evaluation mode, which disables some operations like dropout and batch normalization that are used during training but aren't necessary for evaluation. \n",
    "\n",
    "### Evaluate the model on the Test Dataset:\n",
    "\n",
    "#### Disable gradient calculation\n",
    "* `with torch.no_grad()`: This context manager temporarily disables gradient calculation, as it's not needed for evaluation and can slightly improve performance.\n",
    "\n",
    "#### Loop over the test batches:\n",
    "* `for data in testloader`: This loop iterates over the batches of data provided by the testloader data loader.\n",
    "* `images, labels = data`: Unpacks each batch into input images and corresponding ground truth labels.\n",
    "* `outputs = net(images)`: Feeds the input images through the model to get its predictions.\n",
    "* `_, predicted = torch.max(outputs.data, 1)`: Finds the class with the highest probability for each image (the model's predicted class).\n",
    "* `total += labels.size(0)`: Increments the total number of samples processed.\n",
    "* `correct += (predicted == labels).sum().item()`: Compares the predicted classes with the true labels and counts the number of correct predictions.\n",
    "\n",
    "Finally, we print the calculated accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bc1f92-ee18-4e74-999a-7dacaa678f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "net.eval()  \n",
    "correct = 0 # Initialize counter to zero\n",
    "total = 0 # Initialize counter to zero\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a56804-55a1-4fdf-a895-5bee1f564796",
   "metadata": {},
   "source": [
    "## Get predictions from our model\n",
    "\n",
    "The code in the next cell will perform the following steps:\n",
    "\n",
    "1. Import libraries (matplotlib.pyplot and numpy)\n",
    "1. Define the classes for mapping to numerical representations in source dataset ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "1. Define a function to display images from the dataset. This function takes an image as input and displays it using Matplotlib's imshow function. It also un-normalizes the image pixels, which are often normalized between 0 and 1 during preprocessing, to display them correctly, and converts the image tensor to a NumPy array, which is compatible with Matplotlib.\n",
    "1. Get some random testing images and labels\n",
    "1. Print the images and their ground truth\n",
    "1. Predict labels for the images and print them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104de48a-2176-4e8d-b814-f43d763b2963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Class labels in CIFAR-10\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Get some random testing images\n",
    "dataiter = iter(testloader) # Create an iterator over the test dataset using the testloader data loader.\n",
    "images, labels = next(dataiter) # Get the next batch of images and their corresponding ground truth labels from the iterator.\n",
    "\n",
    "# Print images\n",
    "imshow(torchvision.utils.make_grid(images)) # Create a grid of the images \n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]}' for j in range(4))) # Print the ground truth labels of the displayed images.\n",
    "\n",
    "# Predict labels for the images\n",
    "outputs = net(images)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]}'\n",
    "                              for j in range(4)))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m113"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
