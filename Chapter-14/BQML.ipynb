{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "320cbe5c-c1d2-4a62-a5d4-6904a205816b",
   "metadata": {},
   "source": [
    "# BigQuery ML (BQML)\n",
    "\n",
    "In this notebook, we will use BQML to train and evaluate a linear regression model to predict the fare amount for a given taxi trip, based on the data contained in the New York City Taxi Trips public dataset in BigQuery.\n",
    "\n",
    "**This notebook uses the BigQuery feature dataset and view that we created in the Feature Store activities in Chapter 7. If you deleted those resources, you can create them again by performing the Feature Store activities (in the `feature_store.ipynb` notebook file) in Chapter 7 again.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "**Note:** This notebook and repository are supporting artifacts for the \"Google Machine Learning and Generative AI for Solutions Architects\" book. The book describes the concepts associated with this notebook, and for some of the activities, the book contains instructions that should be performed before running the steps in the notebooks. Each top-level folder in this repo is associated with a chapter in the book. Please ensure that you have read the relevant chapter sections before performing the activities in this notebook.\n",
    "\n",
    "**There are also important generic prerequisite steps outlined [here](https://github.com/PacktPublishing/Google-Machine-Learning-for-Solutions-Architects/blob/main/Prerequisite-steps/Prerequisites.ipynb).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95821d-7f47-44e4-9959-b45d38570967",
   "metadata": {},
   "source": [
    "**Attention:** The code in this notebook creates Google Cloud resources that can incur costs.\n",
    "\n",
    "Refer to the Google Cloud pricing documentation for details.\n",
    "\n",
    "For example:\n",
    "\n",
    "* [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)\n",
    "* [BigQuery Pricing](https://cloud.google.com/bigquery/pricing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f488f6-3745-406a-b727-fb7e12be6906",
   "metadata": {},
   "source": [
    "## Install and import libraries\n",
    "\n",
    "Let's begin by installing and importing the BigQuery Python client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cce2c9-2cd1-4cc5-9361-94f524b8b23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4350d",
   "metadata": {},
   "source": [
    "*The pip installation commands sometimes report various errors. Those errors usually do not affect the activities in this notebook, and you can ignore them.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5092e06-64ed-485f-9e24-e1198271b83f",
   "metadata": {},
   "source": [
    "## Restart the kernel\n",
    "\n",
    "The code in the next cell will retart the kernel, which is sometimes required after installing/upgrading packages.\n",
    "\n",
    "**When prompted, click OK to restart the kernel.**\n",
    "\n",
    "The sleep command simply prevents further cells from executing before the kernel restarts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecdc6f2-9d80-43c5-8710-ab19fd3a05f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "import time\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n",
    "\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fefcdf0-4ef3-4895-8700-347f8cdeceef",
   "metadata": {},
   "source": [
    "# (Wait for kernel to restart before proceeding...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed6aab-ab90-4f69-b6d7-3293174cc9a4",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ec60a-9dcf-415d-bcfb-566dc58e911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec1c534-09a1-49e1-a6a5-3fd1b0417081",
   "metadata": {},
   "source": [
    "## Set Google Cloud resource variables\n",
    "\n",
    "The following code will set variables specific to your Google Cloud resources that will be used in this notebook, such as the Project ID, Region, and GCS Bucket.\n",
    "\n",
    "**Note: This notebook is intended to execute in a Vertex AI Workbench Notebook, in which case the API calls issued in this notebook are authenticated according to the permissions (e.g., service account) assigned to the Vertex AI Workbench Notebook.**\n",
    "\n",
    "We will use the `gcloud` command to get the Project ID details from the local Google Cloud project, and assign the results to the PROJECT_ID variable. If, for any reason, PROJECT_ID is not set, you can set it manually or change it, if preferred.\n",
    "\n",
    "We also use a default bucket name for most of the examples and activities in this book, which has the format: `{PROJECT_ID}-aiml-sa-bucket`. You can change the bucket name if preferred.\n",
    "\n",
    "Also, we're defaulting to the **us-central1** region, but you can optionally replace this with your [preferred region](https://cloud.google.com/about/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae6de65-79e8-46ba-a1e8-2959d22f96dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID_DETAILS = !gcloud config get-value project\n",
    "PROJECT_ID = PROJECT_ID_DETAILS[0]  # The project ID is item 0 in the list returned by the gcloud command\n",
    "REGION=\"us-central1\" # Optional: replace with your preferred region (See: https://cloud.google.com/about/locations) \n",
    "print(f\"Project ID: {PROJECT_ID}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1592827-4f0c-442c-beb7-04e18f2bb58e",
   "metadata": {},
   "source": [
    "## Begin implementation\n",
    "\n",
    "Now that we have performed the prerequisite steps for this activity, it's time to implement the activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1e14e2-309c-4cda-aacf-c0b11395550d",
   "metadata": {},
   "source": [
    "## Define constants and variables\n",
    "\n",
    "The code in the following cell creates constants and variables that will be used throughout the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbd68ff-d44b-4602-ad02-610b5d2844f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "API_ENDPOINT = f\"{REGION}-aiplatform.googleapis.com\"\n",
    "\n",
    "# Specify the public dataset and table\n",
    "public_project_name = 'bigquery-public-data'\n",
    "public_dataset_name = 'new_york_taxi_trips'\n",
    "public_table_name = 'tlc_yellow_trips_2020'\n",
    "public_table_id = f\"{public_project_name}.{public_dataset_name}.{public_table_name}\"\n",
    "\n",
    "# Define our dataset and view names\n",
    "# Feature store view we created in Chapter 7: \n",
    "feature_dataset_name = 'feature_store_for_nyc_taxi_data'\n",
    "feature_view_name = 'nyc_taxi_data_view'\n",
    "feature_view_id = f\"{PROJECT_ID}.{feature_dataset_name}.{feature_view_name}\"\n",
    "# Extended view to combine engineered features with original dataset\n",
    "extended_view_name = 'extended_nyc_taxi_data_view'\n",
    "extended_view_id = f\"{PROJECT_ID}.{feature_dataset_name}.{extended_view_name}\"\n",
    "\n",
    "# Define our model details\n",
    "model_name = 'taxi_fare_model'\n",
    "model_id = f'{feature_dataset_name}.{model_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1399155-7ef1-4377-afb5-10589ac2022d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get the base table from the New York Taxi Trips public dataset in BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f8c6e8-c07b-4ebd-b185-6fec6a779bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Get the table\n",
    "table = client.get_table(public_table_id)\n",
    "\n",
    "# List the field names\n",
    "field_names = [field.name for field in table.schema]\n",
    "\n",
    "# Print the field names\n",
    "print(\"Field Names in the Table:\")\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a749c1a-2347-437d-9ef0-9fc8c29ac280",
   "metadata": {},
   "source": [
    "## Define and create our extended view\n",
    "\n",
    "We will create a new view to train our model. The view will combine the base dataset from the New York Taxi Trips public dataset with the features we engineered in Chapter 7 ([see here for reference](https://github.com/PacktPublishing/Google-Machine-Learning-for-Solutions-Architects/blob/main/Chapter-07/feature-store.ipynb)).\n",
    "\n",
    "First, we define the query that will create the view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6be230-efeb-444a-a2bd-0b827835f7ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extended_view_query = f\"\"\"\n",
    "SELECT\n",
    "  e.pickup_datetime,\n",
    "  e.dropoff_datetime,\n",
    "  e.passenger_count,\n",
    "  e.trip_distance,\n",
    "  e.fare_amount,\n",
    "  e.fare_per_mile,\n",
    "  e.pickup_hour,\n",
    "  e.pickup_day_of_week,\n",
    "  e.dropoff_hour,\n",
    "  e.dropoff_day_of_week,\n",
    "  e.entity_id,\n",
    "  e.feature_timestamp,\n",
    "  o.vendor_id,\n",
    "  o.rate_code,\n",
    "  o.store_and_fwd_flag,\n",
    "  o.payment_type,\n",
    "  o.extra,\n",
    "  o.mta_tax,\n",
    "  o.tip_amount,\n",
    "  o.tolls_amount,\n",
    "  o.imp_surcharge,\n",
    "  o.airport_fee,\n",
    "  o.total_amount,\n",
    "  o.data_file_year,\n",
    "  o.data_file_month,\n",
    "FROM\n",
    "  `{feature_view_id}` AS e\n",
    "JOIN\n",
    "  `{public_table_id}` AS o\n",
    "ON\n",
    "  e.entity_id = CONCAT(o.pickup_datetime, '-', CAST(o.pickup_location_id AS STRING))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce27f6a3-2703-4f1c-abc9-33360e85650a",
   "metadata": {},
   "source": [
    "Next, execute the query that will create the view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e767d2-191a-4820-b097-9c647660266f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.api_core.exceptions import GoogleAPIError\n",
    "\n",
    "extended_view = bigquery.Table(extended_view_id)\n",
    "extended_view.view_query = extended_view_query\n",
    "\n",
    "try:\n",
    "    # Use `exists_ok=True` to avoid 'already exists' error if the view already exists\n",
    "    client.create_table(extended_view, exists_ok=True)\n",
    "    print(f\"View {extended_view_id} created successfully.\")\n",
    "except GoogleAPIError as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf30c82-7009-4f1f-8ade-d45bca82f735",
   "metadata": {},
   "source": [
    "## Verify contents of the extended view\n",
    "\n",
    "The code in the next cell will get our newly created view details and list the fields (or features) in the view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610af9eb-94ca-4d03-94e8-54a4e0b79d26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the table\n",
    "extended_table = client.get_table(extended_view_id)\n",
    "\n",
    "# List the field names\n",
    "extended_field_names = [field.name for field in extended_table.schema]\n",
    "\n",
    "# Print the field names\n",
    "print(\"Field Names in the Table:\")\n",
    "print(extended_field_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe07d82-4fbd-4f21-9fe9-7573d2855de4",
   "metadata": {},
   "source": [
    "## Define the query that will be used to create our linear regression model\n",
    "\n",
    "In the next cell, we define a query that will be used to create our linear regression model. \n",
    "The query selects the features from our extended view (that we created in the previous steps in this notebook) to be used in training our model.\n",
    "It also specifies that the model type is linear regression, and that the target column is `fare_amount`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bd0adf-c226-4e1a-9f21-0586857be2a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_query = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{model_id}`\n",
    "OPTIONS(model_type='linear_reg', input_label_cols=['fare_amount']) AS\n",
    "SELECT\n",
    "  pickup_datetime,\n",
    "  dropoff_datetime,\n",
    "  passenger_count,\n",
    "  trip_distance,\n",
    "  fare_amount,\n",
    "  fare_per_mile,\n",
    "  pickup_hour,\n",
    "  pickup_day_of_week,\n",
    "  dropoff_hour,\n",
    "  dropoff_day_of_week,\n",
    "  vendor_id,\n",
    "  rate_code,\n",
    "  store_and_fwd_flag,\n",
    "  payment_type,\n",
    "  extra,\n",
    "  mta_tax,\n",
    "  tip_amount,\n",
    "  tolls_amount,\n",
    "  imp_surcharge,\n",
    "  airport_fee,\n",
    "  total_amount,\n",
    "  data_file_year,\n",
    "  data_file_month\n",
    "FROM\n",
    "  `{extended_view_id}`;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc30e85a-67d7-40c0-99e0-2598a6ceab43",
   "metadata": {},
   "source": [
    "## Execute the query to create our linear regression model\n",
    "\n",
    "Next, we execute the query that we defined to create our linear regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94686e78-8bea-4e2d-9d51-b5c6365f0899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.api_core.exceptions import NotFound\n",
    "import time\n",
    "\n",
    "# Run the query to create the model and wait for it to start\n",
    "print(\"Starting model training and waiting for completion...\")\n",
    "model_query_job = client.query(model_query)\n",
    "model_query_job.result()  # Wait for the query to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1814f9a-8d73-41ae-bd62-36a5606eb773",
   "metadata": {},
   "source": [
    "## Evaluate our linear regression model\n",
    "\n",
    "Next, we evaluate our linear regression model.\n",
    "\n",
    "The following query will return evaluation metric values for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42145df6-ee29-4eac-a782-4db2c4d1a92a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the SQL query for model evaluation\n",
    "evaluation_query = f\"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL `{model_id}`);\n",
    "\"\"\"\n",
    "\n",
    "# Run the query and store the results in a dataframe \n",
    "evaluation_result = client.query(evaluation_query).to_dataframe()\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(evaluation_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98238f2e-9821-4e7f-9bae-a6872a4173ef",
   "metadata": {},
   "source": [
    "## Get prediction from our model\n",
    "\n",
    "Next, we will get a prediction from our model. In a real world scenario, we would have new data to send to our model. However, to make things easy for demonstration purposes, rather than fabricating new data, we can use existing data to create a new data record that contains all fields except the field that we wish to predict (i.e., the `fare_amount` field).\n",
    "\n",
    "To help understand the code in the next cell, I'll break it down as follows:\n",
    "\n",
    "We will run a SELECT query within a SELECT query. The first SELECT query that executes is:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "      * EXCEPT(fare_amount)\n",
    "    FROM\n",
    "      `{extended_view_id}`\n",
    "    LIMIT 1))\n",
    "```\n",
    "\n",
    "This returns a single record (due to the `LIMIT 1` clause) from our training dataset that contains all fields except the `fare_amount` field. Bear in mind that this is just a convenient way to create a record that we can use in our prediction request. As mentioned above, in a real world scenario, we would have new data to send to our model, and we would not use this trick.\n",
    "\n",
    "The results of that query are then used in our prediction query:\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  predicted_fare_amount\n",
    "FROM\n",
    "  ML.PREDICT(MODEL `{model_id}`, \n",
    "```\n",
    "\n",
    "That query is what requests a prediction from our trained model, and it uses the record from the previous query above as input.\n",
    "\n",
    "Then, we assign the results of our prediction request to a dataframe and we print the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2704a8-0e3a-43e5-9a63-cfa52937a0ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define and run the SQL query for making a prediction\n",
    "prediction_query = f\"\"\"\n",
    "SELECT\n",
    "  predicted_fare_amount\n",
    "FROM\n",
    "  ML.PREDICT(MODEL `{model_id}`, \n",
    "    (SELECT\n",
    "      * EXCEPT(fare_amount)\n",
    "    FROM\n",
    "      `{extended_view_id}`\n",
    "    LIMIT 1))\n",
    "\"\"\"\n",
    "\n",
    "# Run the prediction query and convert to DataFrame\n",
    "prediction_result = client.query(prediction_query).to_dataframe()\n",
    "\n",
    "# Display the predicted fare amount\n",
    "print(\"Predicted Fare Amount:\", prediction_result['predicted_fare_amount'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cabaae8-0dfc-4fd5-97a4-959944a7fc72",
   "metadata": {},
   "source": [
    "# That's it! Well Done!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcb76c1-7a07-4d89-ada7-21245c7be5ba",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "\n",
    "When you no longer need the resources created by this notebook. You can delete them as follows.\n",
    "\n",
    "**Note: if you do not delete the resources, you will continue to pay for them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cefbb9b-3110-4a1f-8e5b-6655568efd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = False  # Set to True if you want to delete the resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf7da1-b4de-494d-9130-b62d53041a18",
   "metadata": {},
   "source": [
    "## Delete BigQuery dataset, view, and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc0c71-2676-4dc1-8e4f-c8262193f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "if clean_up:  \n",
    "    try:\n",
    "        client.delete_table(feature_view_id, not_found_ok=True)\n",
    "        print(f\"Deleted view: {feature_view_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting view: {e}\")\n",
    "\n",
    "    try:\n",
    "        client.delete_dataset(feature_dataset_name, delete_contents=True, not_found_ok=True)\n",
    "        print(f\"Deleted dataset: {feature_dataset_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting dataset: {e}\")\n",
    "        \n",
    "    # Delete the model\n",
    "    try:\n",
    "        model_ref = client.get_model(model_id)\n",
    "        client.delete_model(model_ref)\n",
    "        print(f\"Deleted model: {model_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting model: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"clean_up parameter is set to False.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d617da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m121",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m121"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
