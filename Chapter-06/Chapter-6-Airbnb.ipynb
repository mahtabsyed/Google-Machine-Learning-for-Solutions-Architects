{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0318ef6d-bc87-4b53-ac69-eb1c0bb43c0c",
   "metadata": {},
   "source": [
    "# Data Exploration and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95821d-7f47-44e4-9959-b45d38570967",
   "metadata": {},
   "source": [
    "**Attention:** The code in this notebook creates Google Cloud resources that can incur costs.\n",
    "\n",
    "Refer to the Google Cloud pricing documentation for details.\n",
    "\n",
    "For example:\n",
    "\n",
    "* [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bde10cd-fdab-4613-8ec1-df101c1f6df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with required imports, and read the dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "source_dataset = \"./data/AB_NYC_2019.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(source_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0318ef6d-bc87-4b53-ac69-eb1c0bb43c0c",
   "metadata": {},
   "source": [
    "## Explore dataset and perform some analysis with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fa115c-dd38-42bc-a414-9def028a8584",
   "metadata": {},
   "source": [
    "Display the first few rows of the dataset to get a glimpse of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6528b6-3642-4970-aaa0-5038e55fac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb39fb-3503-4013-a21d-b243d077dc14",
   "metadata": {},
   "source": [
    "One of the first things we will often want to check when exploring a new dataset is what kinds of data (i.e., the schema) exist in there, and whether it looks like there are any missing data entries.\n",
    "\n",
    "Let's get a summary of the dataset, including the number of non-null entries and data types (schema) for each column. We expect the id column to be populated in all of the rows in the dataset, so for any other columns that do not have the same number of non-null entries as the id column, it indicates that those columns may be missing some entries, which could cause problems if we were to train a machine learning model on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd75cbf-ab9c-4eec-8538-2f74ee197160",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803672a5-f81a-4ad7-bf78-e1aee4f71b04",
   "metadata": {},
   "source": [
    "We also usually want to see some descriptive statistics for the columns in order to give us a better understanding of the contents of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15b1ef-0ab4-4831-937d-a11fd0f4cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d851a8-9b93-46e3-9e0e-b83e46a1995e",
   "metadata": {},
   "source": [
    "If we look at statistics such as the minumum, maximum, and mean values, we can see that the features are on different scales. For example, the maximum value for price is 10000, but the maximum value for reviews pr month is 58. We'll come back to this later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73983332-388a-492a-a53d-56f868d09d36",
   "metadata": {},
   "source": [
    "Let's also find the number of unique values for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93985c8-81f2-4a07-9898-7e718e310758",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd4735c-6574-45c0-bf23-2c442efcef90",
   "metadata": {},
   "source": [
    "After checking some of the basics, we can now start to do some more advanced data analysis to get additional insights from the data...\n",
    "\n",
    "Let's display the top 10 neighborhoods with the most Airbnb listings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2050ec69-1c0d-4982-9a61-fd63ae7c5831",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['neighbourhood'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77353fa-2eb9-4df8-a490-03b24696d8db",
   "metadata": {},
   "source": [
    "Calculate the average price for each room type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f320d-dc8a-409f-870b-efebff2fe14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('room_type')['price'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef5a63c-d3f0-4c41-b00c-eb408ddd5880",
   "metadata": {},
   "source": [
    "Find the top 10 hosts with the most listings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8fb98f-bf8a-42f4-9c55-f45bdae9ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['host_id'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f3427f-a5b2-4e9b-a0ce-f7ab4fbc71d0",
   "metadata": {},
   "source": [
    "Calculate the percentage of listings for each room type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1375d54-9c3f-4dd2-b1a4-4efcca070a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['room_type'].value_counts() / data.shape[0]) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31f196b-891a-4451-9e6a-481f1ce28650",
   "metadata": {},
   "source": [
    "Find the average price per neighborhood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24570b-c2b1-4e03-bf18-f1d840c170d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('neighbourhood')['price'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8e57c-0ce5-40b2-9210-efc6a109beeb",
   "metadata": {},
   "source": [
    "Calculate the average availability (in days) for each room type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8029aef7-dc2c-49f2-9b50-dbdeb8ed4617",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('room_type')['availability_365'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d00b3c-8ea0-4355-95d6-292a89fe6273",
   "metadata": {},
   "source": [
    "## Further exploration and visualization with matplotlib and seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42627322-0f1b-45d7-a048-f0c2a57d3eca",
   "metadata": {},
   "source": [
    "Let's start to visualize some of the characteristics of our dataset.\n",
    "We'll start by creating a histogram to show the distribution of prices and help identify potential outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8450ac-7017-4708-8e08-fbd14db2474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data['price'], bins=100)\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(1,1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4235112-3d99-45eb-b886-0ac132c0c836",
   "metadata": {},
   "source": [
    "As we can see, the majority of the accommodation options cost less than 200 USD. There are a some datapoints (but not many) between 600 and 1000 USD. Those are either very expensive accommodation options, or they could be potential outliers/errors in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b13615-d601-4260-a731-2b1b9c2fd1ec",
   "metadata": {},
   "source": [
    "Now, let's see how many different kinds of rooms types exist in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91516d89-2099-4b30-9447-2b7723a22200",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=data, x='room_type')\n",
    "plt.title('Room Type Distribution')\n",
    "plt.xlabel('Room Type')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edbabd7-8887-46a4-a0d1-d81562a72473",
   "metadata": {},
   "source": [
    "As we would expect, the majority of options are entire homes/apartments, followed closely by private rooms, and very few of the options are shared rooms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a0675-5c6e-49e5-bb73-03af7ff3572d",
   "metadata": {},
   "source": [
    "Now, let's review the distribution of minimum nights in the postings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4433442-34a6-4b1e-b303-90e3eeab5e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data['minimum_nights'], bins=100)\n",
    "plt.title('Minimum Nights Distribution')\n",
    "plt.xlabel('Minimum Nights')\n",
    "plt.ylabel('Count')\n",
    "plt.xlim(1,400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f5584-b910-4dd6-a578-16fd8429c161",
   "metadata": {},
   "source": [
    "This is interesting: there are some datapoints above 50 nights. This would be quite unusual for Airbnb, so this could indicate the potential presence of outliers or errors in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e07299-c3cb-43fd-af2a-240c0d5823a8",
   "metadata": {},
   "source": [
    "# Clean up the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca84579a-1c08-4667-a083-99c3369617e2",
   "metadata": {},
   "source": [
    "Now, let's clean up some of the potential issues we identified during our exploration above, such as missing values and outliers. If we assume that this data will be used to train a machine learning model, then these kinds of cleaning steps are usually necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec5e09-4814-42bd-9049-57f2906877da",
   "metadata": {},
   "source": [
    "Use-case: prepare the data for a regression model that will try to predict the nightly room price rate based on the listing's other features.\n",
    "\n",
    "Firstly, we want to handle missing values. In this dataset, the 'host_id' and 'host_name' columns have missing values. We can fill the missing 'host_id' values with the column mode (most frequent value) and drop the rows with missing 'host_name' values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98edb104-a378-4efa-958c-1d141282fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing host_id values with the mode\n",
    "host_id_mode = data['host_id'].mode()[0]\n",
    "data['host_id'].fillna(host_id_mode, inplace=True)\n",
    "\n",
    "# Drop rows with missing host_name values\n",
    "data.dropna(subset=['host_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236d3619-4bf7-485e-a56d-f93d6ba876cc",
   "metadata": {},
   "source": [
    "In fact, we now also realize that some of the features in the dataset would not be valuable for training a machine learning model. For example, the following features are not likely to affect the price:  'id', 'name', 'host_name', 'last_review', and 'reviews_per_month'.\n",
    "\n",
    "Let's remove those columns from our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7885db42-c434-40fe-b9fb-b9498167f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['id', 'name', 'host_name', 'last_review', 'reviews_per_month']\n",
    "data_cleaned = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852e334d-ab8c-40da-aade-be589aa0f66a",
   "metadata": {},
   "source": [
    "Now let's remove the price outliers, because they could inaccurately skew an ML model that's trained on this data. We can remove listings with extremely high or low prices by setting a reasonable price range. In this example, we'll consider listings with prices between 10 USD and 800 USD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71dfb83-3559-4430-8751-f57a93f7bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_range = (data_cleaned['price'] >= 10) & (data_cleaned['price'] <= 800)\n",
    "data_cleaned = data_cleaned.loc[price_range]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b5cf41-d459-455d-bbec-d5284818a9ad",
   "metadata": {},
   "source": [
    "Let's also remove outliers in 'minimum_nights': we can cap the 'minimum_nights' column at an appropriate value, such as 30 days, to remove extreme outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1121fc49-304d-4f0e-8bd2-b44bca678d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned['minimum_nights'] = np.where(data_cleaned['minimum_nights'] > 30, 30, data_cleaned['minimum_nights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14253eeb-2f25-400f-a5bd-da505039e017",
   "metadata": {},
   "source": [
    "# Additional preprocessing for regression use-case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335c290-4190-460f-8f66-dd332d3273ab",
   "metadata": {},
   "source": [
    "In addition to the clean up that we've performed, let's also perform some data transformations that will prepare the data for an ML use-case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e4371a-5334-422a-80bc-48f2f7ad1ebb",
   "metadata": {},
   "source": [
    "First, let's define our target variable (denoted as y) and separate that from the rest of the features (denoted as X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e6c9d-8cb9-4f93-aaec-8f40752c0b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "features = ['neighbourhood_group', 'neighbourhood', 'latitude', 'longitude',\n",
    "            'room_type', 'minimum_nights', 'number_of_reviews',\n",
    "            'calculated_host_listings_count', 'availability_365']\n",
    "target = 'price'\n",
    "\n",
    "X = data_cleaned[features]\n",
    "y = data_cleaned[target]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4945f07-ea07-44e5-a6e8-bb98275d1421",
   "metadata": {},
   "source": [
    "Predicting the price is an example of a regression use-case. For regression use-cases, we want to convert all of the categorical (i.e., non-numeric) features in our dataset into numeric values, and we can use something called One-hot encoding to do that, which can be performed with the pandas [get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2c58db-bd27-48f0-ba93-a98578e14bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded = pd.get_dummies(X, columns=['neighbourhood_group', 'neighbourhood', 'room_type'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0f4578-94c0-4210-aa83-8f47a7e2c90b",
   "metadata": {},
   "source": [
    "As we saw in the statistical distributions of our column values earlier in this notebook, the numerical features in our dataset are on very different scales. This could inaccurately skew an ML model that's trained on this data, because it might think that the larger scale features are more important or impactful. To remove this potential problem, we will change all of the numerical features to be on a standard scale. We can use the StandardScaler class from scikit-learn for this purpose. For more information, see [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea2fa2-c85e-47eb-bb45-6bbff192acc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_features = ['latitude', 'longitude', 'minimum_nights', 'number_of_reviews',\n",
    "                      'calculated_host_listings_count', 'availability_365']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_encoded[numerical_features] = scaler.fit_transform(X_encoded[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32236c-e47a-436d-96e2-ffcb2595a129",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1368a5-f5e1-411c-bc7c-95b0577bb8c2",
   "metadata": {},
   "source": [
    "Now our dataset should be ready to use for training a regression model. We'll leave that activity for another time. In large companies, the tasks of preparing data and training models are often separated, and performed by different people or teams."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
