{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4816bfa-5bff-43d5-984e-7100009dbd19",
   "metadata": {},
   "source": [
    "# Implementing a multi-layer perceptron in TensorFlow and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51122cb4-9a0a-448d-92b9-2271e8424166",
   "metadata": {},
   "source": [
    "Our code in the first cell of the notebook imports the necessary libraries and modules, loads a dataset using the make_moons function from sklearn.datasets, and then visualizes the data using matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e95821d-7f47-44e4-9959-b45d38570967",
   "metadata": {},
   "source": [
    "**Attention:** The code in this notebook creates Google Cloud resources that can incur costs.\n",
    "\n",
    "Refer to the Google Cloud pricing documentation for details.\n",
    "\n",
    "For example:\n",
    "\n",
    "* [Vertex AI Pricing](https://cloud.google.com/vertex-ai/pricing)\n"
   ]
  },
{
   "cell_type": "markdown",
   "id": "42518795-ffa4-4c3f-a5c5-0e76438c0b34",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f96f677-eccf-42cb-a2b9-48be925511ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Required for older versions of Tensorflow\n",
    "!pip uninstall protobuf -y\n",
    "!pip install protobuf==3.19.* --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4350d",
   "metadata": {},
   "source": [
    "*The pip installation commands sometimes report various errors. Those errors do not affect the activities in this notebook, and you can ignore them.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5092e06-64ed-485f-9e24-e1198271b83f",
   "metadata": {},
   "source": [
    "## Restart the kernel\n",
    "\n",
    "The code in the next cell will retart the kernel, which is sometimes required after installing/upgrading packages.\n",
    "\n",
    "**When prompted, click OK to restart the kernel.**\n",
    "\n",
    "The sleep command simply prevents further cells from executing before the kernel restarts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fefcdf0-4ef3-4895-8700-347f8cdeceef",
   "metadata": {},
   "source": [
    "# (Wait for kernel to restart before proceeding...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc036740-4123-470d-b9f4-dc10e100b45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load a simple dataset\n",
    "X, y = make_moons(n_samples=1000, noise=0.2, random_state=42)\n",
    "\n",
    "# generate 2d classification dataset\n",
    "X, y = make_moons(n_samples=1000, noise=0.1)\n",
    "\n",
    "# scatter plot, dots colored by class value\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X[y == 0, 0], X[y == 0, 1], color='red', alpha=0.5)\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', alpha=0.5)\n",
    "\n",
    "# add title and labels\n",
    "plt.title('Moons Dataset')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b06ff6c-2bae-4b24-8405-b6685fe5de43",
   "metadata": {},
   "source": [
    "Next, our code does the following:\n",
    "* Splits the dataset into a training set and a test set.\n",
    "* Defines a Sequential model (which means that the layers are stacked on top of each other).\n",
    "* Adds an input layer and the first hidden layer with 32 neurons and 'relu' activation function. We will discuss this activation function in more detail later in this chapter.\n",
    "* Adds the second hidden layer with 32 neurons and 'relu' activation function.\n",
    "* Adds the output layer with 1 neuron (for binary classification) and 'sigmoid' activation function. We will also discuss this activation function in more detail later in this chapter.\n",
    "* Compiles the model with 'adam' optimizer and 'binary_crossentropy' loss function (suitable for binary classification). We will discuss optimizers in more detail later in this chapter.\n",
    "* Trains the model for 50 epochs\n",
    "\n",
    "*Ignore any errors related to CUDA because we are not usnig GPUs here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c88f580-e856-4f8a-9806-011aa97b5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the data for easier training\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer and the first hidden layer\n",
    "model.add(Dense(32, input_shape=(2,), activation='relu'))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30ae387-ea6e-42d1-8e01-62c391ed9ab6",
   "metadata": {},
   "source": [
    "Next, our code does the following:\n",
    "* Evaluates our model using the model.evaluate method, which returns the loss value and metric values (in this case, accuracy) for the model, in test mode.\n",
    "* Gets some predictions from our model using the model.predict method, which outputs the probabilities that each input sample belongs to the positive class.\n",
    "* In order to treat this as a binary classification use case, our code then converts these probabilities into binary class labels based on a threshold of 0.5 (i.e., anything with a probability of more than 0.5 is deemed to be a member of the positive class).\n",
    "* Finally, we print out the first ten predictions for a quick check. These will be in the form of 0s and 1s, denoting the predicted class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd455ef0-9cb5-455a-be56-a49a47652a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities into class labels\n",
    "y_pred = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Print some predictions for a sanity check\n",
    "print('Predictions:', y_pred[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56417115-b6b1-4bcc-997e-65c3af9c460e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
